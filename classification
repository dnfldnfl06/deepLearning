# source:https://github.com/msyim/VGG16
#some changes

import torch
import torch.nn as tnn
import torchvision
import torchvision.transforms as transforms
import numpy as np


BATCH_SIZE = 16
LEARNING_RATE = 0.001
EPOCH = 100
N_CLASSES = 10

transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean = [ 0.485, 0.456, 0.406 ],
                         std  = [ 0.229, 0.224, 0.225 ]),
    ])

trainData = torchvision.datasets.CIFAR10(root = './data',
            train=True, download=True,transform = transform)
testData = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)

trainLoader = torch.utils.data.DataLoader(dataset = trainData, batch_size=BATCH_SIZE,
                                          shuffle=True, num_workers=4)
#batch_size split data size

testLoader = torch.utils.data.DataLoader(dataset = testData, batch_size=BATCH_SIZE,
                                         shuffle=False, num_workers=4)
#for using sequence list

def conv_layer(ch_in, ch_out, k_size, p_size):
    layer = tnn.Sequential(
        tnn.Conv2d(ch_in, ch_out, kernel_size=k_size, padding = p_size),
        tnn.BatchNorm2d(ch_out),
        tnn.ReLU()
        )
    return layer


def vgg_conv_block(in_list, out_list, k_list, p_list, pooling_k, pooling_s):
    
    layers = [conv_layer(in_list[i], out_list[i], k_list[i], p_list[i]) for i in range(len(in_list))]
    layers += [tnn.MaxPool2d(kernel_size = pooling_k, stride = pooling_s)]
    return tnn.Sequential(*layers)


def vgg_fc_layer(size_in, size_out):
    layer = tnn.Sequential(
        tnn.Linear(size_in, size_out),
        tnn.BatchNorm1d(size_out),
        tnn.ReLU()
        )
    
    return layer


class VGG16(tnn.Module):
    def __init__(self, n_classes=10):
        super(VGG16, self).__init__()
        
        #Conv blocks (BatchNorm + ReLU activation added in each block)
        #                        ch_in_list, ch_out_list,kernel_list,pading_list,pooling_kernel_size, pooling_stride
        self.layer1 = vgg_conv_block([3,64], [64,64], [3,3], [1,1], 2, 2) #pool1
        self.layer2 = vgg_conv_block([64,128], [128,128], [3,3], [1,1], 2, 2)
        self.layer3 = vgg_conv_block([128,256,256], [256,256,256], [3,3,3], [1,1,1], 2, 2)
        self.layer4 = vgg_conv_block([256,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)
        self.layer5 = vgg_conv_block([512,512,512], [512,512,512], [3,3,3], [1,1,1], 1, 1)
        
        #FC layers
        self.layer6 = vgg_fc_layer(2*2*512, 1024)
        self.layer7 = vgg_fc_layer(1024,1024)#1.825672
        
        #Final layer
        self.layer8 = tnn.Linear(1024, n_classes)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = self.layer3(out)
        out = self.layer4(out)
        vgg16_features = self.layer5(out)
        out = vgg16_features.view(out.size(0),-1)
        out = self.layer6(out)
        out = self.layer7(out)
        out = self.layer8(out)
        
        return vgg16_features, out

vgg16 = VGG16(n_classes=N_CLASSES)
vgg16.cuda()

#Loss, Optimizer & Scheduler
cost = tnn.CrossEntropyLoss()
optimizer = torch.optim.Adam(vgg16.parameters(),lr=LEARNING_RATE) #study more Adam 
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer) # lr = lr*factor => r  using this r for get 
#Reduce On Plateau: https://www.deeplearningwizard.com/deep_learning/boosting_models_pytorch/lr_scheduling/

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
vgg16.to(device)

#for test model


accuracy = [0]*EPOCH


for epoch in range(EPOCH): #data set repeating
    
    avg_loss = 0
    cnt = 0
    correct = 0
    total = 0

    for i, data in enumerate(trainLoader, 0):
        # [inputs, labels] from data
        images, labels = data[0].to(device), data[1].to(device)
        
        #make Graidient to 0
        optimizer.zero_grad()
        
        _,outputs = vgg16(images) #_,
        loss = cost(outputs, labels)
        avg_loss += loss.data
        cnt+=1
        print("[E: %d] loss: %f, avg_loss: %f" % (epoch, loss.data, avg_loss/cnt))
        loss.backward()
        optimizer.step()
    scheduler.step(avg_loss)   

    for images, labels in testLoader:
        images = images.cuda()
        _, outputs = vgg16(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted.cpu() == labels).sum()
        accuracy[epoch] = 100*correct/total


vgg16.eval()
correct = 0
total = 0

for images, labels in testLoader:
    images = images.cuda()
    _, outputs = vgg16(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted.cpu() == labels).sum()
    print(predicted, labels, correct, total)
    print("avg acc: %f" % (100* correct/total))

# Save the Trained Model
torch.save(vgg16.state_dict(), 'cnn.pkl')
acc_data = np.array(accuracy) 
np.savez("accuracy_data",acc_data)






